{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c914ca7-9dfe-4062-bfba-e5fd08b53636",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "delta_path = \"/Volumes/workspace/default/santader_lab3(for4)\"\n",
    "santander_df = spark.read.format(\"delta\").load(delta_path)\n",
    "\n",
    "print(\"Rows:\", santander_df.count())\n",
    "display(santander_df.limit(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2641dfc-1609-4dd0-9a43-8f7fb3d0ae4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target_col = \"target\"\n",
    "feature_col = \"scaled_features\"\n",
    "\n",
    "santander_df = santander_df.filter(col(target_col).isNotNull())\n",
    "\n",
    "pdf = santander_df.select(feature_col, target_col).toPandas()\n",
    "\n",
    "X = np.vstack(pdf[feature_col].values)\n",
    "y = pdf[target_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b7bd747-8693-448a-b8af-a2083841eac2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "dict(zip(unique, counts))\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.50,\n",
    "    random_state=42,\n",
    "    stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1386f085-5147-46e9-8927-a7c60e22ae6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class_weight = \"balanced\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4a3330b-7882-4907-b512-7cd1a80405bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(\"Запуск GridSearchCV з урахуванням дисбалансу...\")\n",
    "\n",
    "param_grid_santander = {\n",
    "    \"n_estimators\": [300, 500],\n",
    "    \"max_depth\": [8, 12, 16],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"class_weight\": [\"balanced_subsample\"]\n",
    "}\n",
    "\n",
    "grid_santander = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    param_grid=param_grid_santander,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_santander.fit(X_train, y_train)\n",
    "\n",
    "print(\"Найкращі параметри:\")\n",
    "print(grid_santander.best_params_)\n",
    "\n",
    "best_rf = grid_santander.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3db712df-ceb3-47c4-b716-c158c3768a57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "metrics = []\n",
    "\n",
    "# =============================================\n",
    "# 1. Logistic Regression (balanced)\n",
    "# =============================================\n",
    "lr = LogisticRegression(\n",
    "    max_iter=500,\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"liblinear\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "y_prob_lr = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics.append((\n",
    "    \"LogReg\",\n",
    "    accuracy_score(y_test, y_pred_lr),\n",
    "    f1_score(y_test, y_pred_lr),\n",
    "    roc_auc_score(y_test, y_prob_lr)\n",
    "))\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# 2. Decision Tree (balanced)\n",
    "# =============================================\n",
    "dt = DecisionTreeClassifier(\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "y_prob_dt = dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics.append((\n",
    "    \"Decision Tree\",\n",
    "    accuracy_score(y_test, y_pred_dt),\n",
    "    f1_score(y_test, y_pred_dt),\n",
    "    roc_auc_score(y_test, y_prob_dt)\n",
    "))\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# 3. Random Forest (tuned + class_weight )\n",
    "# =============================================\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=best_rf.n_estimators,\n",
    "    max_depth=best_rf.max_depth,\n",
    "    min_samples_split=best_rf.min_samples_split,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics.append((\n",
    "    \"Random Forest (tuned)\",\n",
    "    accuracy_score(y_test, y_pred_rf),\n",
    "    f1_score(y_test, y_pred_rf),\n",
    "    roc_auc_score(y_test, y_prob_rf)\n",
    "))\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# 4. Gradient Boosting \n",
    "# =============================================\n",
    "gbr = GradientBoostingClassifier(\n",
    "    n_estimators=150,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    subsample=0.8,\n",
    "    max_features=\"sqrt\"\n",
    ")\n",
    "\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gbr = gbr.predict(X_test)\n",
    "y_prob_gbr = gbr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics.append((\n",
    "    \"Gradient Boosting\",\n",
    "    accuracy_score(y_test, y_pred_gbr),\n",
    "    f1_score(y_test, y_pred_gbr),\n",
    "    roc_auc_score(y_test, y_prob_gbr)\n",
    "))\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# Порівняння моделей\n",
    "# =============================================\n",
    "results = pd.DataFrame(metrics, columns=[\"Model\", \"Accuracy\", \"F1-score\", \"ROC-AUC\"])\n",
    "display(results)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2be3677-0b74-4a10-918a-b7d0372391e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# Важливість ознак (RF)\n",
    "# =============================================\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "feat_importance_df = pd.DataFrame({\n",
    "    \"feature\": [f\"feat_{i}\" for i in range(X.shape[1])],\n",
    "    \"importance\": importances\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "display(feat_importance_df.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37e9b0ad-dadd-4f3e-9ef3-097ff190918e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f51bc3ed-c36a-451e-afaf-99976f1909ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# SHAP інтерпретація\n",
    "# =============================================\n",
    "\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "X_sample = X_test[:1500]\n",
    "\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values_1 = shap_values[1]\n",
    "else:\n",
    "    shap_values_1 = shap_values\n",
    "\n",
    "shap.summary_plot(shap_values_1, X_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdfbce13-f1f9-423a-91a5-c716a73ab1d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# FULL METRICS (для Random Forest)\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(\"====================================================\")\n",
    "print(\"      FULL METRICS FOR BEST MODEL (Random Forest)\")\n",
    "print(\"====================================================\")\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_rf)\n",
    "prec = precision_score(y_test, y_pred_rf)\n",
    "rec = recall_score(y_test, y_pred_rf)\n",
    "f1 = f1_score(y_test, y_pred_rf)\n",
    "roc = roc_auc_score(y_test, y_prob_rf)\n",
    "\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall: {rec:.3f}\")\n",
    "print(f\"F1-score: {f1:.3f}\")\n",
    "print(f\"ROC-AUC: {roc:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0771bf5-1b42-4c3d-bc2f-6891da6fe676",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFUSION MATRIX\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix — Random Forest\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf1bc49f-e02d-4444-9a19-b0ae8683116a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# ROC CURVE\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob_rf)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC-AUC = {roc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random guess\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve — Random Forest\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee0f005c-8b5c-456f-a26b-57386b5bf32b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PRECISION–RECALL (PR) CURVE\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, _ = precision_recall_curve(y_test, y_prob_rf)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot(recalls, precisions)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"PR Curve — Random Forest\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "377019ab-90c4-456b-a1aa-92ef93f6b18f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# CALIBRATION CURVE\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_prob_rf, n_bins=10)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(prob_pred, prob_true, marker='o')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel(\"Mean predicted probability\")\n",
    "plt.ylabel(\"True fraction of positives\")\n",
    "plt.title(\"Calibration Curve — Random Forest\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d10ef5e8-f079-44d7-8bc6-556133478bd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FEATURE IMPORTANCE (bar plot)\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(range(len(importances)), importances)\n",
    "plt.title(\"Feature Importance — Random Forest\")\n",
    "plt.xlabel(\"Feature index\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f67ac66-c46d-4de6-aec0-e9d345b17049",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " #============================================================\n",
    "#  METRICS FOR TRAIN / VALIDATION / TEST — Random Forest\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "def compute_metrics(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    y_prob = model.predict_proba(X)[:, 1]\n",
    "    return (\n",
    "        accuracy_score(y, y_pred),\n",
    "        f1_score(y, y_pred, zero_division=0),\n",
    "        roc_auc_score(y, y_prob)\n",
    "    )\n",
    "\n",
    "# ---- TRAIN ----\n",
    "train_acc, train_f1, train_auc = compute_metrics(best_rf, X_train, y_train)\n",
    "\n",
    "# ---- VALIDATION ----\n",
    "val_acc, val_f1, val_auc = compute_metrics(best_rf, X_val, y_val)\n",
    "\n",
    "# ---- TEST ----\n",
    "test_acc, test_f1, test_auc = compute_metrics(best_rf, X_test, y_test)\n",
    "\n",
    "# ---- SUMMARY TABLE ----\n",
    "metrics_santander = pd.DataFrame([\n",
    "    [\"Random Forest (tuned)\", train_acc, train_f1, train_auc,\n",
    "                             val_acc,   val_f1,   val_auc,\n",
    "                             test_acc,  test_f1,  test_auc]\n",
    "],\n",
    "columns=[\n",
    "    \"Model\",\n",
    "    \"Train_Accuracy\", \"Train_F1\", \"Train_ROC-AUC\",\n",
    "    \"Val_Accuracy\",   \"Val_F1\",   \"Val_ROC-AUC\",\n",
    "    \"Test_Accuracy\",  \"Test_F1\",  \"Test_ROC-AUC\"\n",
    "])\n",
    "\n",
    "display(metrics_santander)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "santander_lab_4,5",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
