{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecd0214d-eb3b-4c97-9b2c-11c473d40efc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. ЗАВАНТАЖЕННЯ ДАНИХ\n",
    "# ============================================================\n",
    "\n",
    "delta_input_path = \"/Volumes/workspace/default/olist_delta_3\"\n",
    "olist_df = spark.read.format(\"delta\").load(delta_input_path)\n",
    "\n",
    "print(\"Rows:\", olist_df.count())\n",
    "display(olist_df.limit(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c85e8cb-9e4a-434d-b213-8f882577ef5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. ВИБІР ФІЧ ТА ЦІЛЬОВОЇ ЗМІННОЇ\n",
    "# ============================================================\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "target_col = \"delivery_time_days_calc\"\n",
    "\n",
    "feature_cols = [\n",
    "    \"num_1\", \"num_2\", \"num_3\", \"num_4\", \"num_6\",\n",
    "    \"delivery_diff_avg\", \"fast_delivery\", \"num_1_sq\",\n",
    "    \"num2_num3_interaction\", \"num_mean_12\", \"log_num_1\",\n",
    "    \"purchase_year\", \"purchase_month\", \"purchase_day\"\n",
    "]\n",
    "\n",
    "olist_df = olist_df.filter(col(target_col).isNotNull())\n",
    "\n",
    "# Перехід у pandas\n",
    "pdf = olist_df.select(feature_cols + [target_col]).toPandas()\n",
    "\n",
    "X = pdf[feature_cols].values\n",
    "y = pdf[target_col].values\n",
    "\n",
    "# ============================================================\n",
    "# 3. РОЗБИТТЯ TRAIN / VALIDATION / TEST = 70% / 15% / 15%\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Спочатку train + temp (70% train, 30% temp)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42\n",
    ")\n",
    "\n",
    "# Тепер temp → validation + test (15% / 15%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Validation:\", X_val.shape)\n",
    "print(\"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb7fdd0d-38f6-468e-88b9-7ea0ef666919",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. МАСШТАБУВАННЯ (лише train — val/test трансформуються)\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "results = []\n",
    "\n",
    "# ---------- Лінійна регресія ----------\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "results.append((\n",
    "    \"Linear Regression\",\n",
    "    mean_squared_error(y_test, y_pred) ** 0.5,\n",
    "    mean_absolute_error(y_test, y_pred),\n",
    "    r2_score(y_test, y_pred)\n",
    "))\n",
    "\n",
    "# ---------- Decision Tree ----------\n",
    "dt = DecisionTreeRegressor(max_depth=8, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "results.append((\n",
    "    \"Decision Tree\",\n",
    "    mean_squared_error(y_test, y_pred) ** 0.5,\n",
    "    mean_absolute_error(y_test, y_pred),\n",
    "    r2_score(y_test, y_pred)\n",
    "))\n",
    "\n",
    "# ---------- Random Forest ----------\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=150,\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "results.append((\n",
    "    \"Random Forest\",\n",
    "    mean_squared_error(y_test, y_pred) ** 0.5,\n",
    "    mean_absolute_error(y_test, y_pred),\n",
    "    r2_score(y_test, y_pred)\n",
    "))\n",
    "\n",
    "# ---------- Gradient Boosting ----------\n",
    "gbr = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    random_state=42\n",
    ")\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred = gbr.predict(X_test)\n",
    "\n",
    "results.append((\n",
    "    \"Gradient Boosting\",\n",
    "    mean_squared_error(y_test, y_pred) ** 0.5,\n",
    "    mean_absolute_error(y_test, y_pred),\n",
    "    r2_score(y_test, y_pred)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8f4e509-2f87-451a-a17d-bd57549c08e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6. ФІНАЛЬНА ТАБЛИЦЯ РЕЗУЛЬТАТІВ\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_results = pd.DataFrame(results, columns=[\"Model\", \"RMSE\", \"MAE\", \"R2\"])\n",
    "display(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d415e3b-62c4-4300-a5b1-cbb15b4a0524",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b35fd44e-6686-4af9-96e5-ff7ffdc6dc0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 7. SHAP — ІНТЕРПРЕТАЦІЯ МОДЕЛІ (RandomForest)\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "X_test_sample = X_test[:2000]\n",
    "\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(X_test_sample)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test_sample, feature_names=feature_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30804064-1d2f-420b-8b55-9674f7a4e080",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 5.1 ДОДАТКОВИЙ АНАЛІЗ: Метрики на TRAIN / VALIDATION / TEST\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "def eval_regression(model, X_tr, y_tr, X_v, y_v, X_te, y_te, name):\n",
    "    y_pred_train = model.predict(X_tr)\n",
    "    y_pred_val   = model.predict(X_v)\n",
    "    y_pred_test  = model.predict(X_te)\n",
    "\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "\n",
    "        \"Train_RMSE\": (mean_squared_error(y_tr, y_pred_train)) ** 0.5,\n",
    "        \"Train_MAE\": mean_absolute_error(y_tr, y_pred_train),\n",
    "        \"Train_R2\": r2_score(y_tr, y_pred_train),\n",
    "\n",
    "        \"Val_RMSE\": (mean_squared_error(y_v, y_pred_val)) ** 0.5,\n",
    "        \"Val_MAE\": mean_absolute_error(y_v, y_pred_val),\n",
    "        \"Val_R2\": r2_score(y_v, y_pred_val),\n",
    "\n",
    "        \"Test_RMSE\": (mean_squared_error(y_te, y_pred_test)) ** 0.5,\n",
    "        \"Test_MAE\": mean_absolute_error(y_te, y_pred_test),\n",
    "        \"Test_R2\": r2_score(y_te, y_pred_test),\n",
    "    }\n",
    "\n",
    "# Лінійна регресія\n",
    "metrics_lr = eval_regression(\n",
    "    lr,\n",
    "    X_train_scaled, y_train,\n",
    "    X_val_scaled, y_val,\n",
    "    X_test_scaled, y_test,\n",
    "    \"Linear Regression\"\n",
    ")\n",
    "\n",
    "# Decision Tree\n",
    "metrics_dt = eval_regression(\n",
    "    dt,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    X_test, y_test,\n",
    "    \"Decision Tree\"\n",
    ")\n",
    "\n",
    "# Random Forest\n",
    "metrics_rf = eval_regression(\n",
    "    rf,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    X_test, y_test,\n",
    "    \"Random Forest\"\n",
    ")\n",
    "\n",
    "# Gradient Boosting\n",
    "metrics_gbr = eval_regression(\n",
    "    gbr,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    X_test, y_test,\n",
    "    \"Gradient Boosting\"\n",
    ")\n",
    "\n",
    "df_split_metrics = pd.DataFrame([metrics_lr, metrics_dt, metrics_rf, metrics_gbr])\n",
    "display(df_split_metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd843f0c-7f0d-496d-86f1-d4a551ea3d51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. ACTUAL vs PREDICTED (Random Forest)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.4)\n",
    "plt.plot(\n",
    "    [y_test.min(), y_test.max()],\n",
    "    [y_test.min(), y_test.max()],\n",
    "    'r--'\n",
    ")\n",
    "plt.xlabel(\"Real Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs Predicted — Random Forest\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aab232fe-adcb-4e64-8587-36298936dc8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. РОЗПОДІЛ ПОМИЛОК (RESIDUALS)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "errors = y_test - y_pred_rf\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(errors, bins=50, kde=True)\n",
    "plt.title(\"Distribution of Prediction Errors (Residuals)\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b9e8a5f-be61-4248-9059-74b772ff6a3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. RESIDUALS vs PREDICTED\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(y_pred_rf, errors, alpha=0.4)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.title(\"Residuals vs Predicted\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f6eeae1-eb49-49bf-800e-0ce94edb3699",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 4. FEATURE IMPORTANCE (Random Forest)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(feature_cols)), importances[indices])\n",
    "plt.xticks(range(len(feature_cols)),\n",
    "           [feature_cols[i] for i in indices],\n",
    "           rotation=45, ha='right')\n",
    "plt.title(\"Feature Importance — Random Forest\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2d2adad-2f83-481f-9757-817f17eeb770",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 5. LEARNING CURVE (Random Forest)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    rf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 7),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "train_rmse = (-train_scores.mean(axis=1)) ** 0.5\n",
    "val_rmse   = (-val_scores.mean(axis=1)) ** 0.5\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_rmse, 'o-', label=\"Train RMSE\")\n",
    "plt.plot(train_sizes, val_rmse, 'o-', label=\"Validation RMSE\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Learning Curve — Random Forest\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efe3acc3-1667-4a08-935f-aba062c4356a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 6. SHAP INTERPRETATION (Random Forest)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "shap.initjs()\n",
    "X_sample = X_test[:1500]\n",
    "\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    X_sample,\n",
    "    feature_names=feature_cols\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "olist_lab_4,5",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
